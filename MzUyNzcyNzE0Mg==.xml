<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>深度学习与图网络 | wechat-feeds</title><link>http://MzUyNzcyNzE0Mg.favicon.privacyhide.com/favicon.ico</link><description>关注图网络、图表示学习，最近顶会顶刊动态以及机器学习基本方法，包括无监督学习、半监督学习、弱监督学习、元学习等</description><managingEditor> (hellodword)</managingEditor><pubDate>Sat, 12 Jun 2021 23:21:59 +0800</pubDate><image><url>http://MzUyNzcyNzE0Mg.favicon.privacyhide.com/favicon.ico</url><title>深度学习与图网络 | wechat-feeds</title><link>http://MzUyNzcyNzE0Mg.favicon.privacyhide.com/favicon.ico</link><width>64</width><height>64</height></image><item><title>所有曾经吹过的风，都可以在图网络等以很快的速度再吹一遍 || 2021年，深度学习还有哪些未饱和、有潜力且处于上升期的研究方向？</title><link>https://mp.weixin.qq.com/s/KJBfICTllWkUqB4bUzYLBA</link><description></description><content:encoded><![CDATA[所有曾经吹过的风，都可以在图网络等以很快的速度再吹一遍 || 2021年，深度学习还有哪些未饱和、有潜力且处于上升期的研究方向？]]></content:encoded><pubDate>Sat, 12 Jun 2021 23:17:25 +0800</pubDate></item><item><title>2021年了，学NLP还有出路吗？</title><link>https://mp.weixin.qq.com/s/3mSczfas0-7W3M5512L9FQ</link><description></description><content:encoded><![CDATA[2021年了，学NLP还有出路吗？]]></content:encoded><pubDate>Thu, 10 Jun 2021 20:29:05 +0800</pubDate></item><item><title>ICLR2021 | 近期必读图神经网络精选论文</title><link>https://mp.weixin.qq.com/s/5bJGCQ5OaRzFMLSi_V_LEg</link><description></description><content:encoded><![CDATA[ICLR2021 | 近期必读图神经网络精选论文]]></content:encoded><pubDate>Thu, 10 Jun 2021 20:29:05 +0800</pubDate></item><item><title>ICML2021 | 突破图神经网络中消息传递的限制</title><link>https://mp.weixin.qq.com/s/k469YDkq2QsFVgBYIWZCBg</link><description></description><content:encoded><![CDATA[ICML2021 | 突破图神经网络中消息传递的限制]]></content:encoded><pubDate>Wed, 09 Jun 2021 21:53:02 +0800</pubDate></item><item><title>ICML2021 | 基于子图结构的GNN解释模型</title><link>https://mp.weixin.qq.com/s/BFecSwrymQTAFUoAExywGg</link><description></description><content:encoded><![CDATA[ICML2021 | 基于子图结构的GNN解释模型]]></content:encoded><pubDate>Wed, 09 Jun 2021 21:53:02 +0800</pubDate></item><item><title>JK-Net：残差链接增加图神经网络深度</title><link>https://mp.weixin.qq.com/s/UB4c2cz5qr0zhumLj9nQKQ</link><description></description><content:encoded><![CDATA[JK-Net：残差链接增加图神经网络深度]]></content:encoded><pubDate>Tue, 08 Jun 2021 21:22:54 +0800</pubDate></item><item><title>导师吐槽大会开始：自己招的学生，哭着也要带完</title><link>https://mp.weixin.qq.com/s/8l55H0MzhI8ufDx4hlTaAg</link><description></description><content:encoded><![CDATA[导师吐槽大会开始：自己招的学生，哭着也要带完]]></content:encoded><pubDate>Tue, 08 Jun 2021 21:22:54 +0800</pubDate></item><item><title>突破消息传递图神经网络的限制——ICML2021 | 图神经网络相关论文一览</title><link>https://mp.weixin.qq.com/s/oXSclThhz0kRl9sxrt_Fmg</link><description></description><content:encoded><![CDATA[突破消息传递图神经网络的限制——ICML2021 | 图神经网络相关论文一览]]></content:encoded><pubDate>Mon, 07 Jun 2021 13:25:40 +0800</pubDate></item><item><title>140页，初学者友好，GraphSAGE第一作者William Hamilton书《图表示学习》开放下载</title><link>https://mp.weixin.qq.com/s/Ro0cbv7SBh9NWAMnsdQYTw</link><description></description><content:encoded><![CDATA[140页，初学者友好，GraphSAGE第一作者William Hamilton书《图表示学习》开放下载]]></content:encoded><pubDate>Sun, 06 Jun 2021 21:35:42 +0800</pubDate></item><item><title>ICML 2021 | 论文接收列表一览(100/1184): 基于子图探索的图神经网络可解释性研究:</title><link>https://mp.weixin.qq.com/s/SUhMr4Lr6ojsVgonS3C29A</link><description></description><content:encoded><![CDATA[ICML 2021 | 论文接收列表一览(100/1184): 基于子图探索的图神经网络可解释性研究:]]></content:encoded><pubDate>Sat, 05 Jun 2021 16:50:31 +0800</pubDate></item><item><title>妙啊｜在类别不平衡的上进行半监督学习</title><link>https://mp.weixin.qq.com/s/y5HkKGwxz4jbk9nicwEuUA</link><description></description><content:encoded><![CDATA[妙啊｜在类别不平衡的上进行半监督学习]]></content:encoded><pubDate>Sat, 05 Jun 2021 16:50:31 +0800</pubDate></item><item><title>深入浅出带你读懂图卷积神经网络原理和pytorch代码实现</title><link>https://mp.weixin.qq.com/s/0zGX7ufk9z1HrG1IQOsKEA</link><description></description><content:encoded><![CDATA[深入浅出带你读懂图卷积神经网络原理和pytorch代码实现]]></content:encoded><pubDate>Thu, 03 Jun 2021 22:51:52 +0800</pubDate></item><item><title>SIGIR&#39;21|SGL基于图自监督学习的推荐系统</title><link>https://mp.weixin.qq.com/s/dompKSjN72b7SvGCh2U75A</link><description></description><content:encoded><![CDATA[SIGIR'21|SGL基于图自监督学习的推荐系统]]></content:encoded><pubDate>Thu, 03 Jun 2021 22:51:52 +0800</pubDate></item><item><title>ICLR2020 workshop | 新的研究点1：基于能量的图神经网络</title><link>https://mp.weixin.qq.com/s/wFvfZVpyAc4PZUCmkdErEQ</link><description></description><content:encoded><![CDATA[ICLR2020 workshop | 新的研究点1：基于能量的图神经网络]]></content:encoded><pubDate>Wed, 02 Jun 2021 20:17:06 +0800</pubDate></item><item><title>新的研究点2 图联邦学习| FedGL：具有全局自我监督的联合图学习框架</title><link>https://mp.weixin.qq.com/s/jmFhhFs9Fk6PQvB12SJ7eg</link><description></description><content:encoded><![CDATA[新的研究点2 图联邦学习| FedGL：具有全局自我监督的联合图学习框架]]></content:encoded><pubDate>Wed, 02 Jun 2021 20:17:06 +0800</pubDate></item><item><title>每天2小时，吃透 985博士总结的这份保姆级TensorFlow + PyTorch笔记（20G高清/PPT/代码)</title><link>https://mp.weixin.qq.com/s/JwAdAV7uNQ3ADavZ8HTEtw</link><description></description><content:encoded><![CDATA[每天2小时，吃透 985博士总结的这份保姆级TensorFlow + PyTorch笔记（20G高清/PPT/代码)]]></content:encoded><pubDate>Tue, 01 Jun 2021 11:44:39 +0800</pubDate></item></channel></rss>